{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xente Fraud Detection: Feature Engineering\n",
    "Competition : https://zindi.africa/competitions/xente-fraud-detection-challenge\n",
    "\n",
    "Problem statement: Create a machine learning model to detect fraudulent transactions.\n",
    "\n",
    "Predict `FraudResult` probability\n",
    "\n",
    "Evaluation: The error metric for this competition is the `F1 score`, which ranges from 0 (total failure) to 1 (perfect score). Hence, the closer your score is to 1, the better your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to visualise al the columns in the dataframe\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# to display all the columns of the dataframe in the notebook\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "In the following cells, I will engineer / pre-process the variables of the Xente Fraud Detection Dataset. I will engineer the variables to address:\n",
    "\n",
    "1. Missing values\n",
    "2. Temporal variables\n",
    "3. Non-Gaussian distributed variables\n",
    "4. Categorical variables: remove rare labels\n",
    "5. Categorical variables: convert strings to numbers\n",
    "5. Standarise the values of the variables to the same range\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_data = pd.read_csv('../data/interim/wrangled_data.csv', parse_dates=['TransactionStartTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset: (140681, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>FraudResult</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>2018-11-15 02:18:49+00:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20.0</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>2018-11-15 02:19:08+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>CustomerId_4683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>2018-11-15 02:44:21+00:00</td>\n",
       "      <td>500</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>utility_bill</td>\n",
       "      <td>ProductId_21</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>2018-11-15 03:32:55+00:00</td>\n",
       "      <td>21800</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-644.0</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>2018-11-15 03:34:21+00:00</td>\n",
       "      <td>644</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Amount    ChannelId       CustomerId  FraudResult  PricingStrategy  \\\n",
       "0   1000.0  ChannelId_3  CustomerId_4406          0.0                2   \n",
       "1    -20.0  ChannelId_2  CustomerId_4406          0.0                2   \n",
       "2    500.0  ChannelId_3  CustomerId_4683          0.0                2   \n",
       "3  20000.0  ChannelId_3   CustomerId_988          0.0                2   \n",
       "4   -644.0  ChannelId_2   CustomerId_988          0.0                2   \n",
       "\n",
       "      ProductCategory     ProductId    ProviderId        TransactionId  \\\n",
       "0             airtime  ProductId_10  ProviderId_6  TransactionId_76871   \n",
       "1  financial_services   ProductId_6  ProviderId_4  TransactionId_73770   \n",
       "2             airtime   ProductId_1  ProviderId_6  TransactionId_26203   \n",
       "3        utility_bill  ProductId_21  ProviderId_1    TransactionId_380   \n",
       "4  financial_services   ProductId_6  ProviderId_4  TransactionId_28195   \n",
       "\n",
       "       TransactionStartTime  Value source  \n",
       "0 2018-11-15 02:18:49+00:00   1000  train  \n",
       "1 2018-11-15 02:19:08+00:00     20  train  \n",
       "2 2018-11-15 02:44:21+00:00    500  train  \n",
       "3 2018-11-15 03:32:55+00:00  21800  train  \n",
       "4 2018-11-15 03:34:21+00:00    644  train  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the size of the dataset\n",
    "print('The size of the dataset: ' + str(df_data.shape))\n",
    "\n",
    "# view some rows\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_data[df_data['source'] == 'train']\n",
    "df_new_data = df_data[df_data['source'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86095, 12), (9567, 12))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's separate into train and test set\n",
    "# Remember to set the seed (random_state for this sklearn function)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, df_train.FraudResult,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=0) # we are setting the seed here\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numerical variable\n",
    "for var in ['Value']:\n",
    "    X_train[var] = np.log(X_train[var])\n",
    "    X_test[var] = np.log(X_test[var])\n",
    "    df_new_data[var]= np.log(df_new_data[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to extract year, month, day, hr, minute to create columns in dataframe\n",
    "def extract_date_features(df):\n",
    "    '''df takes dataframe'''\n",
    "    \n",
    "    df['Transaction_year'] = df['TransactionStartTime'].apply(lambda x: x.year)\n",
    "    df['Transaction_month'] = df['TransactionStartTime'].apply(lambda x: x.month)\n",
    "    df['Transaction_day'] = df['TransactionStartTime'].apply(lambda x: x.day)\n",
    "    df['Transaction_hour'] = df['TransactionStartTime'].apply(lambda x: x.hour)\n",
    "    df['Transaction_minute'] = df['TransactionStartTime'].apply(lambda x: x.minute)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date features\n",
    "extract_date_features(X_train)\n",
    "extract_date_features(X_test)\n",
    "extract_date_features(df_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preserve the transactionid\n",
    "df_train_transaction_ids = X_train['TransactionId']\n",
    "df_test_transaction_ids = X_test['TransactionId']\n",
    "df_new_data_transaction_ids = df_new_data['TransactionId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "X_train.drop(columns=['CustomerId','source','Amount','TransactionStartTime'], inplace=True)\n",
    "X_test.drop(columns=['CustomerId','source','Amount','TransactionStartTime'], inplace=True)\n",
    "df_new_data.drop(columns=['CustomerId','source','Amount','TransactionStartTime'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChannelId', 'ProductCategory', 'ProductId', 'ProviderId', 'TransactionId']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's capture the categorical variables first\n",
    "cat_vars = [var for var in X_train.columns if X_train[var].dtype == 'O']\n",
    "cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_vars = ['ChannelId', 'ProductCategory', 'ProductId', 'ProviderId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function will assign discrete values to the strings of the variables, \n",
    "# so that the smaller value corresponds to the smaller mean of target\n",
    "\n",
    "def replace_categories(train, test,new_data, var, target):\n",
    "    ordered_labels = train.groupby([var])[target].mean().sort_values().index\n",
    "    ordinal_label = {k:i for i, k in enumerate(ordered_labels, 0)} \n",
    "    train[var] = train[var].map(ordinal_label)\n",
    "    test[var] = test[var].map(ordinal_label)\n",
    "    new_data[var] = new_data[var].map(ordinal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    replace_categories(X_train, X_test, df_new_data, var, 'FraudResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['TransactionId'] = df_train_transaction_ids\n",
    "X_test['TransactionId'] = df_test_transaction_ids\n",
    "df_new_data['TransactionId'] = df_new_data_transaction_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of na\n",
    "[var for var in X_train.columns if X_train[var].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check absence of na\n",
    "[var for var in X_test.columns if X_test[var].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = [var for var in X_train.columns if var not in ['TransactionId', 'FraudResult']]\n",
    "len(train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train[['TransactionId', 'FraudResult']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit scaler\n",
    "scaler = MinMaxScaler() # create an instance\n",
    "scaler.fit(X_train[train_vars]) #  fit  the scaler to the train set for later use\n",
    "\n",
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "X_train = pd.concat([X_train[['TransactionId', 'FraudResult']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(X_train[train_vars]), columns=train_vars)],\n",
    "                    axis=1)\n",
    "\n",
    "X_test = pd.concat([X_test[['TransactionId', 'FraudResult']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(X_test[train_vars]), columns=train_vars)],\n",
    "                    axis=1)\n",
    "\n",
    "df_new_data = pd.concat([df_new_data[['TransactionId', 'FraudResult']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(df_new_data[train_vars]), columns=train_vars)],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check absence of missing values\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the train and test sets for the next notebook!\n",
    "X_train.to_csv(\"../data/processed/x_train.csv\",index=False)\n",
    "X_test.to_csv(\"../data/processed/x_test.csv\",index=False)\n",
    "df_new_data.to_csv(\"../data/processed/new_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
